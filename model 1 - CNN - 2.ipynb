{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import os, sys\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 960 (CNMeM is disabled, cuDNN 5103)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['THEANO_FLAGS'] = \"device=gpu\"    \n",
    "import theano\n",
    "theano.config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The load_path function loads the .jpg image and converts it to a numpy array. \n",
    "# It also extracts the image label from path and places it into file_array\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "def load_data(paths):\n",
    "    \n",
    "    X = []\n",
    "    file_array = []\n",
    "    label_array = []\n",
    "  \n",
    "    # Images are resized because they range from 720-924 and 1192-1280 Making it difficult to use in models\n",
    "    # and neural networks\n",
    "    # Most 'common' original image size\n",
    "    # The 'im.resize' switches these dimensions. That is why they are backwards here.\n",
    "    size = 1280, 720\n",
    "    \n",
    "    print('..loading images')\n",
    "    start = time.time()\n",
    "    \n",
    "    # if loading 'training set' also extract label from file\n",
    "        \n",
    "    for path in glob.glob(paths):\n",
    "\n",
    "        try:\n",
    "            # load image and convert to np array\n",
    "            im = Image.open(path)\n",
    "            im = im.resize((size[0], size[1]))\n",
    "            im = np.asarray(im)\n",
    "            X.append(im)\n",
    "\n",
    "            # extract file name EX: img_00003.jpg\n",
    "            base = os.path.basename(path)\n",
    "            file_array.append(base)\n",
    "\n",
    "            if 'train' in paths:\n",
    "                # extract fish label (ALB, BET, DOL, LAG, NoF, OTEHR, SHARK, YFT)\n",
    "                directory = os.path.split(path)[0]\n",
    "                label_array.append(os.path.split(directory)[1])\n",
    "\n",
    "        except IOError:\n",
    "            print \"cannot load or resize image for '%s'\" % path\n",
    "\n",
    "\n",
    "    print('time elapsed: ' + str(time.time() - start))\n",
    "\n",
    "    if 'train' in paths:\n",
    "        return X, file_array, label_array\n",
    "\n",
    "    else:\n",
    "        return X, file_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert label_array containing m number of labels, in this case, 8 different types of fish, to a one-hot encoded array\n",
    "def convert_to_one_hot(label_array):\n",
    "    n = len(label_array) #number of samples\n",
    "    m = 8 #number of types of fish\n",
    "    \n",
    "    classification_array = np.zeros(n)\n",
    " \n",
    "    # assign numerical label to each type of fish\n",
    "    for sample in xrange(n):\n",
    "        \n",
    "        if label_array[sample] == 'ALB':\n",
    "            classification_array[sample] = 0\n",
    "            \n",
    "        elif label_array[sample] == 'BET':\n",
    "            classification_array[sample] = 1\n",
    "            \n",
    "        elif label_array[sample] == 'DOL':\n",
    "            classification_array[sample] = 2\n",
    "        \n",
    "        elif label_array[sample] == 'LAG':\n",
    "            classification_array[sample] = 3\n",
    "            \n",
    "        elif label_array[sample] == 'NoF':\n",
    "            classification_array[sample] = 4\n",
    "            \n",
    "        elif label_array[sample] == 'OTHER':\n",
    "            classification_array[sample] = 5\n",
    "            \n",
    "        elif label_array[sample] == 'SHARK':\n",
    "            classification_array[sample] = 6\n",
    "            \n",
    "        elif label_array[sample] == 'YFT':\n",
    "            classification_array[sample] = 7\n",
    "            \n",
    "    # covert array to to one-hot encoded array        \n",
    "    one_hot_array = np.eye(m)[classification_array.astype(int)]\n",
    "            \n",
    "    return classification_array, one_hot_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def shuffle_X_and_Y(X, Y):\n",
    "    # Given list X and list Y\n",
    "    X_shuf = []\n",
    "    Y_shuf = []\n",
    "    index_shuf = range(len(X))\n",
    "    shuffle(index_shuf)\n",
    "    \n",
    "    for i in index_shuf:\n",
    "        X_shuf.append(X[i])\n",
    "        Y_shuf.append(label_array[i])\n",
    "        \n",
    "    return(X_shuf, Y_shuf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..loading images\n",
      "time elapsed: 94.3899998665\n"
     ]
    }
   ],
   "source": [
    "X, file_array, label_array = load_data('F:/Kaggle/The Nature Conservancy/train/train/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_array, Y = convert_to_one_hot(label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_numbers = np.zeros(8)\n",
    "for i in xrange(8):\n",
    "    label_numbers[i] = np.sum(classification_array==i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try un-skewing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_unskew = []\n",
    "label_unskew = []\n",
    "\n",
    "index = 0\n",
    "offset = 67\n",
    "for i in xrange(8):\n",
    "    for j in xrange(offset):\n",
    "        X_unskew.append(X[int(index+j)])\n",
    "        label_unskew.append(label_array[int(index+j)])\n",
    "        #print(index+j)\n",
    "    \n",
    "    index += label_numbers[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shuffle_X_and_Y causes all labels to become ALB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, label_array = shuffle_X_and_Y(X, label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_unskew, label_unskew = shuffle_X_and_Y(X_unskew, label_unskew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALB',\n",
       " 'YFT',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'DOL',\n",
       " 'OTHER',\n",
       " 'NoF',\n",
       " 'SHARK',\n",
       " 'YFT',\n",
       " 'SHARK',\n",
       " 'ALB',\n",
       " 'DOL',\n",
       " 'NoF',\n",
       " 'LAG',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'BET',\n",
       " 'ALB',\n",
       " 'BET',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'SHARK',\n",
       " 'OTHER',\n",
       " 'OTHER',\n",
       " 'DOL',\n",
       " 'NoF',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'YFT',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'NoF',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'BET',\n",
       " 'NoF',\n",
       " 'YFT',\n",
       " 'YFT',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'OTHER',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'BET',\n",
       " 'BET',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'OTHER',\n",
       " 'YFT',\n",
       " 'OTHER',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'SHARK',\n",
       " 'SHARK',\n",
       " 'NoF',\n",
       " 'OTHER',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'DOL',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'BET',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'OTHER',\n",
       " 'BET',\n",
       " 'YFT',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'SHARK',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'BET',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'SHARK',\n",
       " 'YFT',\n",
       " 'SHARK',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'OTHER',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'SHARK',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'DOL',\n",
       " 'NoF',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'OTHER',\n",
       " 'ALB',\n",
       " 'LAG',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'BET',\n",
       " 'DOL',\n",
       " 'YFT',\n",
       " 'BET',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'OTHER',\n",
       " 'YFT',\n",
       " 'YFT',\n",
       " 'OTHER',\n",
       " 'NoF',\n",
       " 'NoF',\n",
       " 'OTHER',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'OTHER',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'OTHER',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'OTHER',\n",
       " 'SHARK',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'OTHER',\n",
       " 'YFT',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'BET',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'SHARK',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'SHARK',\n",
       " 'DOL',\n",
       " 'BET',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'OTHER',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'OTHER',\n",
       " 'NoF',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'DOL',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'OTHER',\n",
       " 'DOL',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'OTHER',\n",
       " 'YFT',\n",
       " 'NoF',\n",
       " 'BET',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'BET',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'SHARK',\n",
       " 'SHARK',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'BET',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'DOL',\n",
       " 'NoF',\n",
       " 'YFT',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'OTHER',\n",
       " 'YFT',\n",
       " 'DOL',\n",
       " 'SHARK',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'OTHER',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'SHARK',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'BET',\n",
       " 'OTHER',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'YFT',\n",
       " 'DOL',\n",
       " 'YFT',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'BET',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'OTHER',\n",
       " 'YFT',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'BET',\n",
       " 'YFT',\n",
       " 'YFT',\n",
       " 'OTHER',\n",
       " 'NoF',\n",
       " 'YFT',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'OTHER',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'NoF',\n",
       " 'OTHER',\n",
       " 'ALB',\n",
       " 'BET',\n",
       " 'LAG',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'SHARK',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'SHARK',\n",
       " 'OTHER',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'BET',\n",
       " 'BET',\n",
       " 'BET',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'OTHER',\n",
       " 'SHARK',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'OTHER',\n",
       " 'OTHER',\n",
       " 'ALB',\n",
       " 'SHARK',\n",
       " 'OTHER',\n",
       " 'NoF',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'DOL',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'OTHER',\n",
       " 'YFT',\n",
       " 'YFT',\n",
       " 'YFT',\n",
       " 'BET',\n",
       " 'DOL',\n",
       " 'OTHER',\n",
       " 'NoF',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'YFT',\n",
       " 'NoF',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'LAG',\n",
       " 'ALB',\n",
       " 'DOL',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'YFT',\n",
       " 'YFT',\n",
       " 'LAG',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'NoF',\n",
       " 'LAG',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'BET',\n",
       " 'ALB',\n",
       " 'DOL',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'LAG',\n",
       " 'YFT',\n",
       " 'DOL',\n",
       " 'BET',\n",
       " 'YFT',\n",
       " 'NoF',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'DOL',\n",
       " 'DOL',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'SHARK',\n",
       " 'DOL',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'OTHER',\n",
       " 'OTHER',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'SHARK',\n",
       " 'ALB',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'BET',\n",
       " 'OTHER',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'DOL',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'BET',\n",
       " 'NoF',\n",
       " 'OTHER',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'SHARK',\n",
       " 'YFT',\n",
       " 'OTHER',\n",
       " 'BET',\n",
       " 'NoF',\n",
       " 'NoF',\n",
       " 'YFT',\n",
       " 'YFT',\n",
       " 'YFT',\n",
       " 'NoF',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'BET',\n",
       " 'YFT',\n",
       " 'BET',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'ALB',\n",
       " 'BET',\n",
       " 'ALB',\n",
       " 'YFT',\n",
       " 'YFT']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_unskew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_unskew, Y_unskew = convert_to_one_hot(label_unskew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_unskew[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape X for shape samples, channels, rows, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW X_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_unskew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = Y_unskew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Reshape\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple CNN model for CIFAR-10\n",
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720L, 1280L, 3L)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_classes=8\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(64, 5, 5, input_shape=(3, 720, 1280), activation='relu', border_mode='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Convolution2D(64, 5, 5, activation='relu', border_mode='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', border_mode='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', border_mode='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', border_mode='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', border_mode='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', border_mode='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', border_mode='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "#model.add(Convolution2D(64, 3, 3, activation='relu', border_mode='same'))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Convolution2D(64, 3, 3, activation='relu', border_mode='same'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Convolution2D(128, 3, 3, activation='relu', border_mode='same'))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Convolution2D(128, 3, 3, activation='relu', border_mode='same'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Convolution2D(256, 3, 3, activation='relu', border_mode='same'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Convolution2D(256, 3, 3, activation='relu', border_mode='same'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(68, activation='relu', W_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu', W_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation='relu', W_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# Compile model\n",
    "epochs = 2\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "#model.fit(X_cnn, Y_batch, nb_epoch=2, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 720, 1280) 4864        convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 64, 720, 1280) 0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 720, 1280) 102464      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 64, 360, 640)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 64, 360, 640)  0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 64, 360, 640)  36928       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 64, 180, 320)  0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 64, 180, 320)  0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 64, 180, 320)  36928       dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 64, 90, 160)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 64, 90, 160)   0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 128, 90, 160)  73856       dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 128, 45, 80)   0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 128, 45, 80)   0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 128, 45, 80)   147584      dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 128, 22, 40)   0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 128, 22, 40)   0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 128, 22, 40)   147584      dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 128, 11, 20)   0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 128, 11, 20)   0           maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 128, 11, 20)   147584      dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_7 (MaxPooling2D)    (None, 128, 5, 10)    0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 128, 5, 10)    0           maxpooling2d_7[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 6400)          0           dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 6400)          0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 68)            435268      dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 68)            0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 32)            2208        dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 32)            0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 16)            528         dropout_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 16)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 8)             136         dropout_12[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1135932\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_cnn = np.zeros([X_train.shape[0], X_train.shape[3], X_train.shape[1], X_train.shape[2]], np.uint8)\n",
    "for samples in xrange(X_train.shape[0]):\n",
    "    for channels in xrange(X_train.shape[3]):\n",
    "        X_cnn[samples,channels,:,:] = X_train[samples,:,:,channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(536L, 3L, 720L, 1280L)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_batch(X, Y, index, batch_size):\n",
    "    X_batch = X[index:index+batch_size,:,:,:]\n",
    "    X_batch = np.float16(X_batch)/255\n",
    "    \n",
    "    Y_batch = Y[index:index+batch_size,:]\n",
    "    return X_batch, Y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large index: 50\n",
      "large index: 100\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "batch_size = 1\n",
    "large_batch_size = 50\n",
    "large_index = 0\n",
    "\n",
    "X_batch_large, Y_batch_large = create_batch(X_cnn, Y, large_index, large_batch_size)\n",
    "\n",
    "while large_index < 100:\n",
    "    while index<X_batch_large.shape[0]:\n",
    "\n",
    "        X_batch = X_batch_large[index:index+batch_size,:,:,:]\n",
    "        Y_batch = Y_batch_large[index:index+batch_size,:]\n",
    "\n",
    "        model.fit(X_batch, Y_batch, nb_epoch=1, batch_size=1, verbose=False)\n",
    "        #model.train_on_batch(X_batch, Y_batch)\n",
    "        index += batch_size\n",
    "    index = 0  \n",
    "    large_index += large_batch_size\n",
    "    X_batch_large, Y_batch_large = create_batch(X_cnn, Y, large_index,\n",
    "                                                large_batch_size)\n",
    "    print('large index: ' + str(large_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(536L, 8L)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..loading images\n",
      "time elapsed: 24.5650000572\n"
     ]
    }
   ],
   "source": [
    "X_test, file_array_test = load_data('F:/Kaggle/The Nature Conservancy/test_stg1/test_stg1/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test2 = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_cnn_test = np.zeros([X_test2.shape[0], X_test2.shape[3], X_test2.shape[1], X_test2.shape[2]], np.uint8)\n",
    "\n",
    "for samples in xrange(X_test2.shape[0]):\n",
    "    for channels in xrange(X_test2.shape[3]):\n",
    "        X_cnn_test[samples,channels,:,:] = X_test2[samples,:,:,channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_cnn_test = X_cnn_test/float(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_predictions = 10\n",
    "test_predictions = numpy.zeros([num_predictions,8])\n",
    "\n",
    "for sample in xrange(num_predictions):\n",
    "    test_predictions[sample,:] = model.predict(X_cnn_test[sample:sample+1,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.45499173,  0.06996741,  0.04279276,  0.02648743,  0.11002259,\n",
       "         0.07945698,  0.04987249,  0.16640861],\n",
       "       [ 0.45499155,  0.06996741,  0.04279279,  0.02648747,  0.11002257,\n",
       "         0.07945704,  0.04987255,  0.16640863],\n",
       "       [ 0.45499125,  0.06996746,  0.04279286,  0.02648754,  0.11002262,\n",
       "         0.07945708,  0.04987262,  0.16640866],\n",
       "       [ 0.45499134,  0.06996744,  0.04279283,  0.02648751,  0.11002259,\n",
       "         0.07945707,  0.04987259,  0.16640861],\n",
       "       [ 0.45499241,  0.06996734,  0.04279261,  0.02648731,  0.11002249,\n",
       "         0.07945693,  0.04987235,  0.1664086 ],\n",
       "       [ 0.4549911 ,  0.06996746,  0.04279287,  0.02648755,  0.11002261,\n",
       "         0.07945709,  0.04987263,  0.16640863],\n",
       "       [ 0.45499194,  0.06996738,  0.04279272,  0.02648739,  0.11002257,\n",
       "         0.07945697,  0.04987247,  0.16640864],\n",
       "       [ 0.45499155,  0.06996745,  0.04279279,  0.02648748,  0.11002258,\n",
       "         0.07945705,  0.04987254,  0.16640854],\n",
       "       [ 0.45499155,  0.06996743,  0.0427928 ,  0.02648748,  0.11002258,\n",
       "         0.07945704,  0.04987255,  0.16640858],\n",
       "       [ 0.45499113,  0.06996746,  0.04279287,  0.02648755,  0.1100226 ,\n",
       "         0.0794571 ,  0.04987263,  0.16640861]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions[:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_prediction = test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_array_test = np.asarray(file_array_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save\n",
    "#test_prediction = numpy.reshape(test_prediction, [len(test_prediction), 1])\n",
    "file_label = numpy.reshape(file_array_test, [len(file_array_test), 1])\n",
    "labels_and_predictions = numpy.append(file_label, test_prediction, axis=1)\n",
    "np.savetxt(\"F:/Kaggle/The Nature Conservancy/submissions/my_submission5.csv\", labels_and_predictions,\n",
    "           delimiter=',',fmt='%s', header= 'image,ALB,BET,DOL,LAG,NoF,OTHER,SHARK,YFT', comments='' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
